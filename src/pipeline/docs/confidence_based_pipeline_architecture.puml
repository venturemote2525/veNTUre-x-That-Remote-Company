@startuml Food Nutrition Analysis Pipeline

!theme cerulean-outline

title Confidence-Based Food Nutrition Analysis Pipeline Architecture

' Define colors for different model types
!define SEGMENTATION_COLOR #87CEEB
!define DEPTH_COLOR #98FB98  
!define NUTRITION_COLOR #FFB6C1
!define INTERFACE_COLOR #F0E68C
!define REFERENCE_COLOR #D8BFD8

' Visual style overrides for readability on dark editors
skinparam BackgroundColor #0E1116
skinparam TitleFontColor #FFFFFF
skinparam DefaultFontColor #FFFFFF
skinparam ArrowColor #FFFFFF
skinparam NoteFontColor #FFFFFF
skinparam NoteBackgroundColor #1A2230
skinparam NoteBorderColor #4A637A
skinparam PackageFontColor #FFFFFF
skinparam PackageBorderColor #4A637A
skinparam ClassFontColor #FFFFFF
skinparam ClassBackgroundColor #1E2A36
skinparam ClassBorderColor #4A637A
skinparam InterfaceBackgroundColor #1E2A36
skinparam InterfaceBorderColor #4A637A

package "Input Processing" {
  class ImageInput {
    + image_path: str
    + image_data: np.ndarray
    + preprocess_image(): np.ndarray
    + validate_input(): bool
  }
}

package "Segmentation Module" SEGMENTATION_COLOR {
  class MaskRCNNSegmentation {
    + model: torch.nn.Module
    + device: str
    + class_names: List[str]
    + load_model(checkpoint_path: str): void
    + segment_image(image: np.ndarray): SegmentationResult
  }
  
  class SegmentationResult {
    + boxes: torch.Tensor
    + masks: torch.Tensor
    + labels: torch.Tensor
    + scores: torch.Tensor
    + get_food_items(): List[FoodItem]
  }
}

package "Depth Estimation" DEPTH_COLOR {
  class DepthAnythingModel {
    + model: DepthAnything
    + device: str
    + encoder: str
    + transform: Compose
    + estimate_depth(image: np.ndarray): np.ndarray
    + get_depth_stats(depth_map: np.ndarray): Dict
  }
  
  class DepthResult {
    + depth_map: np.ndarray
    + depth_stats: Dict
    + visualize_depth(colormap: str): np.ndarray
  }
}

package "Volume Calculation" {
  class VolumeCalculator {
    + camera_params: Dict
    + reference_scale: float
    + set_scale(scale_mm_per_pixel: float): void
    + calculate_volume(mask: np.ndarray, depth: np.ndarray, scale_mm_per_pixel: Optional[float] = None): float
    + estimate_real_world_scale(measurement: ReferenceObjectMeasurement): float
    + get_volume_confidence(volume: float): str
  }
  
  class VolumeResult {
    + volume_ml: float
    + confidence: str
    + mask_area: int
    + avg_depth: float
  }
}

package "Reference Scale" REFERENCE_COLOR {
  interface ReferenceObjectDetectorInterface {
    + detect(image: np.ndarray): List[ReferenceObjectMeasurement]
    + get_supported_objects(): List[str]
  }

  class ReferenceObjectDetector {
    + model: torch.nn.Module
    + segmenter: torch.nn.Module
    + detect(image: np.ndarray): List[ReferenceObjectMeasurement]
  }

  class ReferenceObjectMeasurement {
    + object_type: str
    + bbox: Tuple
    + mask: np.ndarray
    + pixel_length: float
    + known_real_length_mm: float
    + scale_mm_per_pixel: float
    + confidence: float
  }
}

package "Specific Classification" INTERFACE_COLOR {
  interface SpecificClassifierInterface {
    + classify(image: np.ndarray, bbox: Tuple): SpecificClassification
    + classify_whole_image(image: np.ndarray): WholeImageClassification
    + is_available(): bool
    + get_supported_classes(): List[str]
  }
  
  class FriendsSpecificModel {
    + model: torch.nn.Module
    + classify(image: np.ndarray, bbox: Tuple): SpecificClassification
    + classify_whole_image(image: np.ndarray): WholeImageClassification
    + is_available(): bool
  }
  
  class SpecificClassification {
    + specific_class: str
    + confidence: float
    + broad_to_specific_mapping(): Dict
  }
  
  class WholeImageClassification {
    + predicted_class: str
    + confidence: float
    + broad_category: str
    + is_single_item: bool
  }
  
  class ClassificationConfidenceManager {
    + confidence_threshold: float
    + compare_classifications(whole_image: WholeImageClassification, segmented: List[SpecificClassification]): ClassificationDecision
    + calculate_segmented_avg_confidence(classifications: List[SpecificClassification]): float
    + should_use_whole_image_classification(decision: ClassificationDecision): bool
  }
  
  class ClassificationDecision {
    + use_whole_image: bool
    + whole_image_confidence: float
    + segmented_avg_confidence: float
    + confidence_difference: float
    + decision_reason: str
  }
}

package "Nutrition Database" NUTRITION_COLOR {
  class NutritionDatabase {
    + broad_class_nutrition: Dict
    + specific_class_nutrition: Dict
    + food_densities: Dict
    + get_nutrition_broad(class_name: str): NutritionInfo
    + get_nutrition_specific(food_name: str): NutritionInfo
    + get_density(food_name: str): float
  }
  
  class NutritionInfo {
    + calories_per_100g: float
    + protein_g: float
    + carbs_g: float
    + fat_g: float
    + fiber_g: float
    + density_g_ml: float
  }
}

package "Main Pipeline" {
  class NutritionPipeline {
    + segmentation_model: MaskRCNNSegmentation
    + depth_model: DepthAnythingModel
    + volume_calculator: VolumeCalculator
    + reference_detector: ReferenceObjectDetectorInterface
    + specific_classifier: SpecificClassifierInterface
    + confidence_manager: ClassificationConfidenceManager
    + nutrition_db: NutritionDatabase
    + analyze_food_image(image_path: str): NutritionAnalysisResult
    + estimate_scale(image: np.ndarray): Optional[float]
    + process_food_items_with_confidence(): List[FoodItemAnalysis]
    + analyze_whole_image(image: np.ndarray): WholeImageClassification
    + merge_segments_for_whole_analysis(segments: List[FoodItem]): FoodItem
  }
  
  class FoodItem {
    + item_id: int
    + broad_class: str
    + specific_class: Optional[str]
    + confidence_broad: float
    + confidence_specific: Optional[float]
    + whole_image_class: Optional[str]
    + whole_image_confidence: Optional[float]
    + is_merged_segments: bool
    + mask: np.ndarray
    + bbox: Tuple
    + original_segments: Optional[List[FoodItem]]
  }
  
  class FoodItemAnalysis {
    + food_item: FoodItem
    + volume: VolumeResult
    + nutrition: NutritionInfo
    + total_calories: float
    + total_macros: Dict
    + classification_decision: ClassificationDecision
    + analysis_method: str
  }
  
  class NutritionAnalysisResult {
    + image_path: str
    + total_calories: float
    + total_volume_ml: float
    + total_protein_g: float
    + total_carbs_g: float
    + total_fat_g: float
    + food_items: List[FoodItemAnalysis]
    + export_json(): str
    + export_csv(): str
  }
}

package "User Interface" INTERFACE_COLOR {
  class StreamlitNutritionApp {
    + pipeline: NutritionPipeline
    + run_analysis(uploaded_files): void
    + display_results(result: NutritionAnalysisResult): void
    + export_reports(result: NutritionAnalysisResult): void
  }
}

' Relationships
ImageInput --> NutritionPipeline : feeds image
NutritionPipeline --> MaskRCNNSegmentation : uses
NutritionPipeline --> DepthAnythingModel : uses  
NutritionPipeline --> VolumeCalculator : uses
NutritionPipeline --> ReferenceObjectDetectorInterface : uses
NutritionPipeline --> SpecificClassifierInterface : uses
NutritionPipeline --> ClassificationConfidenceManager : uses
NutritionPipeline --> NutritionDatabase : queries

MaskRCNNSegmentation --> SegmentationResult : produces
DepthAnythingModel --> DepthResult : produces
VolumeCalculator --> VolumeResult : produces
ReferenceObjectDetectorInterface <|-- ReferenceObjectDetector : implements
ReferenceObjectDetector --> ReferenceObjectMeasurement : produces
VolumeCalculator ..> ReferenceObjectMeasurement : uses scale
SpecificClassifierInterface <|-- FriendsSpecificModel : implements
FriendsSpecificModel --> SpecificClassification : produces
FriendsSpecificModel --> WholeImageClassification : produces
ClassificationConfidenceManager --> ClassificationDecision : produces
ClassificationConfidenceManager ..> WholeImageClassification : compares
ClassificationConfidenceManager ..> SpecificClassification : compares

NutritionDatabase --> NutritionInfo : provides
NutritionPipeline --> FoodItemAnalysis : creates
FoodItemAnalysis --> NutritionAnalysisResult : aggregated into

StreamlitNutritionApp --> NutritionPipeline : uses
NutritionAnalysisResult --> StreamlitNutritionApp : displays

' Sequence Flow
note right of NutritionPipeline
  **Enhanced Confidence-Based Pipeline Flow:**
  1. Load image
  2. Run segmentation (broad classes) **& whole-image classification in parallel**
  3. Compare confidence scores (whole-image vs segmented)
  4. **DECISION POINT:**
     - If whole-image confidence > segmented: merge segments, use whole-image class
     - If segmented confidence > whole-image: analyze segments individually
  5. Detect reference object(s) and compute scale
  6. Estimate depth map
  7. Calculate volumes (merged or individual based on decision)
  8. Run specific classification (if needed)
  9. Look up nutrition data (broad or specific)
  10. Calculate total nutrition
  11. Generate comprehensive report with confidence metrics
end note

note left of ClassificationConfidenceManager
  **Confidence Decision Logic:**
  
  whole_confidence = whole_image_classification.confidence
  segmented_confidence = avg(segment_confidences)
  
  if whole_confidence > segmented_confidence + threshold:
    → Use whole-image classification
    → Merge all segments for volume calculation
    → Apply single nutrition profile
  else:
    → Use individual segment classifications
    → Calculate volumes per segment
    → Sum individual nutrition profiles
end note

@enduml
